version: "3.8"
services:
  redis:
    # it is importnant to configure OS memory overcommit
    # https://github.com/nextcloud/all-in-one/discussions/1731
    # run this in your VM:
    # echo "vm.overcommit_memory = 1" | sudo tee /etc/sysctl.d/nextcloud-aio-memory-overcommit.conf
    image: redis
    command: redis-server --save 20 1 --loglevel warning
    expose:
      - 6379
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 15s
      retries: 1
    restart: on-failure
    networks:
      default:
        aliases:
          - redis
    volumes:
      - redis:/data
  rabbitmq:
    image: rabbitmq
    command: rabbitmq-server
    hostname: rabbitmq
    expose:
      - 5672
      - 15672
    ports:
      - "5672:5672"
      - "15672:15672"
    volumes:
      - rabbitmq-data:/var/lib/rabbitmq
    environment:
      - RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS=-rabbit consumer_timeout 3600000000
    healthcheck:
      test: ["CMD", "rabbitmqctl", "ping"]
      interval: 5s
      timeout: 15s
      retries: 1
    restart: on-failure
    networks:
      default:
        aliases:
          - rabbitmq
  qdrant:
    image: qdrant/qdrant
    environment:
      - QDRANT__DEBUG=1
      - QDRANT__SERVICE__HOST=0.0.0.0
    ports:
      - "6333:6333"
    volumes:
      - qdrant-data:/qdrant/storage
    restart: on-failure
    networks:
      default:
        aliases:
          - qdrant
  llama-base: # this one is here just to ensure that the base image is created
    build: ./llama-base
    image: aithena-llama-base
    volumes:
      - "../open_llama_7b/:/llama/models/7B/"
  llama-server:
    build: ./llama-server
    ports:
      - "8000:8000"
    volumes:
      - "../open_llama_7b/:/llama/models/"
    restart: on-failure
    cap_add:
      - IPC_LOCK
      - SYS_NICE
    # deploy:
    #   resources:
    #     reservations:
    #       memory: 16G
    #       cpus: "20"
    networks:
      default:
        aliases:
          - llama-server
  embeddings-server:
    build: ./embeddings-server
    environment:
      - PORT=8085
    ports:
      - "8085:8085"
    restart: on-failure
    networks:
      default:
        aliases:
          - embeddings-server
  document-lister:
    build: ./document-lister
    environment:
      - RABBITMQ_HOST=rabbitmq
      - STORAGE_ACCOUNT_NAME=biblaisourcedocs
      - STORAGE_CONTAINER=test-library
      - REDIS_HOST=redis
      - QUEUE_NAME=shortembeddings
    depends_on:
      - rabbitmq
      - redis
    restart: on-failure
    networks:
      - default
  document-indexer:
    build: ./document-indexer
    environment:
      - RABBITMQ_HOST=rabbitmq
      - EMBEDDINGS_HOST=embeddings-server
      - EMBEDDINGS_PORT=8085
      - QDRANT_HOST=qdrant
      - QDRANT_COLLECTION=shortembeddings
      - QDRANT_VECTOR_DIM=768
      - STORAGE_ACCOUNT_NAME=biblaisourcedocs
      - STORAGE_CONTAINER=test-library
      - REDIS_HOST=redis
      - QUEUE_NAME=shortembeddings
    restart: on-failure
    deploy:
      replicas: 1
    depends_on:
      - rabbitmq
      - redis
      - qdrant
      - embeddings-server
    networks:
      - default
  qdrant-search:
    build:
      context: .
      dockerfile: ./qdrant-search/Dockerfile
    ports:
      - "8080:8080"
    restart: on-failure
    depends_on:
      - qdrant
      - llama-server
    environment:
      - PORT=8080
      - QDRANT_HOST=qdrant
      - QDRANT_PORT=6333
      - QDRANT_COLLECTION=shortembeddings
      - QDRANT_VECTOR_DIM=768
      - EMBEDDINGS_HOST=embeddings-server
      - EMBEDDINGS_PORT=8085
      - CHAT_HOST=llama-server
      - CHAT_PORT=8000
      - STORAGE_ACCOUNT_NAME=biblaisourcedocs
      - STORAGE_CONTAINER=test-library
  llama-playground:
    image: ghcr.io/mckaywrigley/chatbot-ui:main
    ports:
      - 3000:3000
    environment:
      - OPENAI_API_HOST=http://llama-server:8000
      - OPENAI_API_KEY=""
  nginx:
    image: nginx:1.15-alpine
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - nginx-data:/etc/nginx/conf.d
      - certbot-data-conf:/etc/letsencrypt
      - certbot-data-www:/var/www/certbot
    command: '/bin/sh -c ''while :; do sleep 6h & wait $${!}; nginx -s reload; done & nginx -g "daemon off;"'''
  certbot:
    image: certbot/certbot
    restart: unless-stopped
    volumes:
      - certbot-data-conf:/etc/letsencrypt
      - certbot-data-www:/var/www/certbot
    entrypoint: "/bin/sh -c 'trap exit TERM; while :; do certbot renew; sleep 12h & wait $${!}; done;'"
volumes:
  rabbitmq-data:
    driver: local
    driver_opts:
      type: "none"
      o: "bind"
      device: "/source/volumes/rabbitmq-data"
  qdrant-data:
    driver: local
    driver_opts:
      type: "none"
      o: "bind"
      device: "/source/volumes/qdrant-data"
  nginx-data:
    driver: local
    driver_opts:
      type: "none"
      o: "bind"
      device: "/source/volumes/nginx-data"
  certbot-data-conf:
    driver: local
    driver_opts:
      type: "none"
      o: "bind"
      device: "/source/volumes/certbot-data/conf"
  certbot-data-www:
    driver: local
    driver_opts:
      type: "none"
      o: "bind"
      device: "/source/volumes/certbot-data/www"
  redis:
    driver: local
    driver_opts:
      type: "none"
      o: "bind"
      device: "/source/volumes/redis"
networks:
  default:
